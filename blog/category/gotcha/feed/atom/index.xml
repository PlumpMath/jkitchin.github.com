<?xml version="1.0" encoding="UTF-8"?>
<feed
  xmlns="http://www.w3.org/2005/Atom"
  xmlns:thr="http://purl.org/syndication/thread/1.0"
  xml:lang="en"
   >
  <title type="text">The Kitchin Research Group</title>
  <subtitle type="text">Chemical Engineering at Carnegie Mellon University</subtitle>

  <updated>2017-01-06T02:12:22Z</updated>
  <generator uri="http://blogofile.com/">Blogofile</generator>

  <link rel="alternate" type="text/html" href="http://jkitchin.github.io/blog" />
  <id>http://jkitchin.github.io/blog/feed/atom/</id>
  <link rel="self" type="application/atom+xml" href="http://jkitchin.github.io/blog/feed/atom/" />
  <entry>
    <author>
      <name></name>
      <uri>http://jkitchin.github.io/blog</uri>
    </author>
    <title type="html"><![CDATA[Potential gotchas in linear algebra in numpy]]></title>
    <link rel="alternate" type="text/html" href="http://jkitchin.github.io/blog/2013/03/12/Potential-gotchas-in-linear-algebra-in-numpy" />
    <id>http://jkitchin.github.io/blog/2013/03/12/Potential-gotchas-in-linear-algebra-in-numpy</id>
    <updated>2013-03-12T22:19:53Z</updated>
    <published>2013-03-12T22:19:53Z</published>
    <category scheme="http://jkitchin.github.io/blog" term="linear algebra" />
    <category scheme="http://jkitchin.github.io/blog" term="gotcha" />
    <summary type="html"><![CDATA[Potential gotchas in linear algebra in numpy]]></summary>
    <content type="html" xml:base="http://jkitchin.github.io/blog/2013/03/12/Potential-gotchas-in-linear-algebra-in-numpy"><![CDATA[


<p>
Numpy has some gotcha features for linear algebra purists. The first is that a 1d array is neither a row, nor a column vector. That is, \(a\) = \(a^T\) if \(a\) is a 1d array. That means you can take the dot product of \(a\) with itself, without transposing the second argument. This would not be allowed in Matlab.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

a = np.array([0, 1, 2])
<span style="color: #8b0000;">print</span> a.shape
<span style="color: #8b0000;">print</span> a
<span style="color: #8b0000;">print</span> a.T

<span style="color: #8b0000;">print</span>
<span style="color: #8b0000;">print</span> np.dot(a, a)
<span style="color: #8b0000;">print</span> np.dot(a, a.T)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; (3L,)
[0 1 2]
[0 1 2]
&gt;&gt;&gt;
5
5
</pre>

<p>
Compare the previous behavior with this 2d array. In this case, you cannot take the dot product of \(b\) with itself, because the dimensions are incompatible. You must transpose the second argument to make it dimensionally consistent. Also, the result of the dot product is not a simple scalar, but a 1 &times; 1 array.
</p>

<div class="org-src-container">

<pre class="src src-python">b = np.array([[0, 1, 2]])
<span style="color: #8b0000;">print</span> b.shape
<span style="color: #8b0000;">print</span> b
<span style="color: #8b0000;">print</span> b.T

<span style="color: #8b0000;">print</span> np.dot(b, b)    <span style="color: #ff0000; font-weight: bold;"># this is not ok, the dimensions are wrong.</span>
<span style="color: #8b0000;">print</span> np.dot(b, b.T)
<span style="color: #8b0000;">print</span> np.dot(b, b.T).shape
</pre>
</div>

<pre class="example">
(1L, 3L)
[[0 1 2]]
[[0]
 [1]
 [2]]
&gt;&gt;&gt; Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
ValueError: objects are not aligned
[[5]]
(1L, 1L)
</pre>

<p>
Try to figure this one out! x is a column vector, and y is a 1d vector. Just by adding them you get a 2d array.
</p>
<div class="org-src-container">

<pre class="src src-python">x = np.array([[2], [4], [6], [8]])
y = np.array([1, 1, 1, 1, 1, 2])
<span style="color: #8b0000;">print</span> x + y
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; [[ 3  3  3  3  3  4]
 [ 5  5  5  5  5  6]
 [ 7  7  7  7  7  8]
 [ 9  9  9  9  9 10]]
</pre>

<p>
Or this crazy alternative way to do the same thing.
</p>
<div class="org-src-container">

<pre class="src src-python">x = np.array([2, 4, 6, 8])
y = np.array([1, 1, 1, 1, 1, 1, 2])

<span style="color: #8b0000;">print</span> x[:, np.newaxis] + y
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; [[ 3  3  3  3  3  3  4]
 [ 5  5  5  5  5  5  6]
 [ 7  7  7  7  7  7  8]
 [ 9  9  9  9  9  9 10]]
</pre>

<p>
In the next example,  we have a 3 element vector and a 4 element vector. We convert \(b\) to a 2D array with np.newaxis, and compute the outer product of the two arrays. The result is a 4 &times; 3 array.
</p>
<div class="org-src-container">

<pre class="src src-python">a = np.array([1, 2, 3])
b = np.array([10, 20, 30, 40])

<span style="color: #8b0000;">print</span> a * b[:, np.newaxis]
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; [[ 10  40  90]
 [ 20  80 180]
 [ 30 120 270]
 [ 40 160 360]]
</pre>

<p>
These concepts are known in numpy as array broadcasting. See <a href="http://www.scipy.org/EricsBroadcastingDoc" >http://www.scipy.org/EricsBroadcastingDoc</a> and <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html" >http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html</a> for more details.
</p>

<p>
These are points to keep in mind, as the operations do not strictly follow the conventions of linear algebra, and may be confusing at times.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/03/12/Potential-gotchas-in-linear-algebra-in-numpy.org">org-mode source</a><p>]]></content>
  </entry>
  <entry>
    <author>
      <name></name>
      <uri>http://jkitchin.github.io/blog</uri>
    </author>
    <title type="html"><![CDATA[Integrating the Fermi distribution to compute entropy]]></title>
    <link rel="alternate" type="text/html" href="http://jkitchin.github.io/blog/2013/03/06/Integrating-the-Fermi-distribution-to-compute-entropy" />
    <id>http://jkitchin.github.io/blog/2013/03/06/Integrating-the-Fermi-distribution-to-compute-entropy</id>
    <updated>2013-03-06T09:47:19Z</updated>
    <published>2013-03-06T09:39:42Z</published>
    <category scheme="http://jkitchin.github.io/blog" term="dft" />
    <category scheme="http://jkitchin.github.io/blog" term="integration" />
    <category scheme="http://jkitchin.github.io/blog" term="gotcha" />
    <summary type="html"><![CDATA[Integrating the Fermi distribution to compute entropy]]></summary>
    <content type="html" xml:base="http://jkitchin.github.io/blog/2013/03/06/Integrating-the-Fermi-distribution-to-compute-entropy"><![CDATA[



<p>
The Fermi distribution is defined by \(f(\epsilon) = \frac{1}{e^{(\epsilon - \mu)/(k T)} + 1}\). This function describes the occupation of energy levels at temperatures above absolute zero. We use this function to compute electronic entropy in a metal, which contains an integral of \(\int n(\epsilon) (f \ln f + (1 - f) \ln (1-f)) d\epsilon\), where \(n(\epsilon)\) is the electronic density of states. Here we plot the Fermi distribution function. It shows that well below the Fermi level the states are fully occupied, and well above the Fermi level, they are unoccupied. Near the Fermi level, the states go from occupied to unoccupied smoothly.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

mu = 0
k = 8.6e-5
T = 1000

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">f</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

espan = np.linspace(-10, 10, 200)
plt.plot(espan, f(espan))
plt.ylim([-0.1, 1.1])
plt.savefig(<span style="color: #228b22;">'images/fermi-entropy-integrand-1.png'</span>)
</pre>
</div>

<p><img src="/img/./images/fermi-entropy-integrand-1.png"><p>

<p>
Let us consider a simple density of states function, just a parabola. This could represent a s-band for example. We will use this function to explore the integral.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

mu = 0
k = 8.6e-5
T = 1000

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">f</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">dos</span>(e):
    d = (np.ones(e.shape) - 0.03 * e**2) 
    <span style="color: #8b0000;">return</span> d * (d &gt; 0)
espan = np.linspace(-10, 10)

plt.plot(espan, dos(espan), label=<span style="color: #228b22;">'Total dos'</span>)
plt.plot(espan, f(espan) * dos(espan), label=<span style="color: #228b22;">'Occupied states'</span>)
plt.legend(loc=<span style="color: #228b22;">'best'</span>)
plt.savefig(<span style="color: #228b22;">'images/fermi-entropy-integrand-2.png'</span>)
</pre>
</div>

<p>
<p><img src="/img/./images/fermi-entropy-integrand-2.png"><p>
Now, we consider the integral to compute the electronic entropy. The entropy is proportional to this integral.
</p>

<p>
\( \int n(\epsilon) (f \ln f + (1 - f) \ln (1-f)) d\epsilon \)
</p>

<p>
It looks straightforward to compute, but it turns out there is a wrinkle. Evaluating the integrand leads to <code>nan</code> elements because the ln(0) is -&infin;. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
mu = 0
k = 8.6e-5
T = 100

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">fermi</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

espan = np.array([-20, -10, -5, 0.0, 5, 10])
f = fermi(espan)

<span style="color: #8b0000;">print</span> f * np.log(f)
<span style="color: #8b0000;">print</span> (1 - f) * np.log(1 - f)
</pre>
</div>

<pre class="example">
[  0.00000000e+000   0.00000000e+000   0.00000000e+000  -3.46573590e-001
  -1.85216532e-250               nan]
[        nan         nan         nan -0.34657359  0.          0.        ]
</pre>

<p>
In this case, these <code>nan</code> elements should be equal to zero (x ln(x) goes to zero as x goes to zero). So, we can just ignore those elements in the integral. Here is how to do that.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

mu = 0
k = 8.6e-5
T = 1000

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">fermi</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">dos</span>(e):
    d = (np.ones(e.shape) - 0.03 * e**2) 
    <span style="color: #8b0000;">return</span> d * (d &gt; 0)

espan = np.linspace(-20, 10)
f = fermi(espan)
n = dos(espan)

g = n * (f * np.log(f) + (1 - f) * np.log(1 - f))

<span style="color: #8b0000;">print</span> np.trapz(espan, g) <span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">nan because of the nan in the g vector</span>
<span style="color: #8b0000;">print</span> g

plt.plot(espan, g)
plt.savefig(<span style="color: #228b22;">'images/fermi-entropy-integrand-3.png'</span>)

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">find the elements that are not nan</span>
ind = np.logical_not(np.isnan(g))

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">evaluate the integrand for only those points</span>
<span style="color: #8b0000;">print</span> np.trapz(espan[ind], g[ind])
</pre>
</div>

<pre class="example">
nan
[             nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
  -9.75109643e-14  -1.05987106e-10  -1.04640574e-07  -8.76265644e-05
  -4.92684641e-02  -2.91047740e-01  -7.75652579e-04  -1.00962241e-06
  -1.06972936e-09  -1.00527877e-12  -8.36436686e-16  -6.48930917e-19
  -4.37946336e-22  -2.23285389e-25  -1.88578082e-29   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00]
0.208886080897
</pre>

<p><img src="/img/./images/fermi-entropy-integrand-3.png"><p>

<p>
The integrand is pretty well behaved in the figure above. You do not see the full range of the x-axis, because the integrand evaluates to <code>nan</code> for very negative numbers. This causes the <code>trapz</code> function to return <code>nan</code> also. We can solve the problem by only integrating the parts that are not <code>nan</code>. We have to use numpy.logical<sub>not</sub> to get an element-wise array of which elements are not <code>nan</code>. In this example, the integrand is not well sampled, so the area under that curve may not be very accurate. 
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/03/06/Integrating-the-Fermi-distribution-to-compute-entropy.org">org-mode source</a><p>]]></content>
  </entry>
</feed>
