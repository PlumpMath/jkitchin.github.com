---
title: Using Lagrange multipliers in optimization
date: 2013/02/03 09:00:00
updated: 2013/02/27 14:43:27
categories: optimization
tags: ''
---


<p>


<a href="http://matlab.cheme.cmu.edu/2011/12/24/using-lagrange-multipliers-in-optimization/" >Matlab post</a>  (adapted from <a href="http://en.wikipedia.org/wiki/Lagrange_multipliers" >http://en.wikipedia.org/wiki/Lagrange_multipliers</a>.)
</p>

<p>
Suppose we seek to maximize the function \(f(x,y)=x+y\) subject to the constraint that \(x^2 + y^2 = 1\). The function we seek to maximize is an unbounded plane, while the constraint is a unit circle. We want the maximum value of the circle, on the plane. We plot these two functions here.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

x = np.linspace(-1.5, 1.5)

[X, Y] = np.meshgrid(x, x)

<span style="color: #8b0000;">import</span> matplotlib <span style="color: #8b0000;">as</span> mpl
<span style="color: #8b0000;">from</span> mpl_toolkits.mplot3d <span style="color: #8b0000;">import</span> Axes3D
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

fig = plt.figure()
ax = fig.gca(projection=<span style="color: #228b22;">'3d'</span>)

ax.plot_surface(X, Y, X + Y)

theta = np.linspace(0,2*np.pi);
R = 1.0
x1 = R * np.cos(theta)
y1 = R * np.sin(theta)

ax.plot(x1, y1, x1 + y1, <span style="color: #228b22;">'r-'</span>)
plt.savefig(<span style="color: #228b22;">'images/lagrange-1.png'</span>)
</pre>
</div>

<p><img src="/img/./images/lagrange-1.png"><p>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Construct the Lagrange multiplier augmented function</h2>
<div class="outline-text-2" id="text-1">
<p>
To find the maximum, we construct the following function: \(\Lambda(x,y; \lambda) = f(x,y)+\lambda g(x,y)\) where \(g(x,y) = x^2 + y^2 - 1 = 0\), which is the constraint function. Since \(g(x,y)=0\), we are not really changing the original function, provided that the constraint is met!
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">func</span>(X):
    x = X[0]
    y = X[1]
    L = X[2] <span style="color: #ff0000; font-weight: bold;"># this is the multiplier. lambda is a reserved keyword in python</span>
    <span style="color: #8b0000;">return</span> x + y + L * (x**2 + y**2 - 1)
</pre>
</div>
</div>
</div>
<div id="outline-container-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Finding the partial derivatives</h2>
<div class="outline-text-2" id="text-2">
<p>
The minima/maxima of the augmented function are located where all of the partial derivatives of the augmented function are equal to zero, i.e. \(\partial \Lambda/\partial x = 0\), \(\partial \Lambda/\partial y = 0\), and \(\partial \Lambda/\partial \lambda = 0\). the process for solving this is usually to analytically evaluate the partial derivatives, and then solve the unconstrained resulting equations, which may be nonlinear.
</p>

<p>
Rather than perform the analytical differentiation, here we develop a way to numerically approximate the partial derivatives.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">def</span> <span style="color: #8b2323;">dfunc</span>(X):
    dLambda = np.zeros(<span style="color: #8b0000;">len</span>(X))
    h = 1e-3 <span style="color: #ff0000; font-weight: bold;"># this is the step size used in the finite difference.</span>
    <span style="color: #8b0000;">for</span> i <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">range</span>(len(X)):
        dX = np.zeros(<span style="color: #8b0000;">len</span>(X))
        dX[i] = h
        dLambda[i] = (func(X+dX)-func(X-dX))/(2*h);
    <span style="color: #8b0000;">return</span> dLambda
</pre>
</div>
</div>
</div>
<div id="outline-container-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> Now we solve for the zeros in the partial derivatives</h2>
<div class="outline-text-2" id="text-3">
<p>
The function we defined above (dfunc) will equal zero at a maximum or minimum. It turns out there are two solutions to this problem, but only one of them is the maximum value. Which solution you get depends on the initial guess provided to the solver. Here we have to use some judgement to identify the maximum.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">from</span> scipy.optimize <span style="color: #8b0000;">import</span> fsolve

<span style="color: #ff0000; font-weight: bold;"># this is the max</span>
X1 = fsolve(dfunc, [1, 1, 0])
<span style="color: #8b0000;">print</span> X1, func(X1)

<span style="color: #ff0000; font-weight: bold;"># this is the min</span>
X2 = fsolve(dfunc, [-1, -1, 0])
<span style="color: #8b0000;">print</span> X2, func(X2)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; ... &gt;&gt;&gt; [ 0.70710678  0.70710678 -0.70710678] 1.41421356237
&gt;&gt;&gt; ... &gt;&gt;&gt; [-0.70710678 -0.70710678  0.70710678] -1.41421356237
</pre>
</div>
</div>
<div id="outline-container-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Summary</h2>
<div class="outline-text-2" id="text-4">
<p>
Three dimensional plots in matplotlib are a little more difficult than in Matlab (where the code is almost the same as 2D plots, just different commands, e.g. plot vs plot3). In Matplotlib you have to import additional modules in the right order, and use the object oriented approach to plotting as shown here.</p>
</div>
</div>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/03/Using-Lagrange-multipliers-in-optimization.org">org-mode source</a><p>