---
title: Integrating the Fermi distribution to compute entropy
date: 2013/03/06 09:39:42
updated: 2013/03/06 09:47:19
categories: dft, integration, gotcha
tags: 
---



<p>
The Fermi distribution is defined by \(f(\epsilon) = \frac{1}{e^{(\epsilon - \mu)/(k T)} + 1}\). This function describes the occupation of energy levels at temperatures above absolute zero. We use this function to compute electronic entropy in a metal, which contains an integral of \(\int n(\epsilon) (f \ln f + (1 - f) \ln (1-f)) d\epsilon\), where \(n(\epsilon)\) is the electronic density of states. Here we plot the Fermi distribution function. It shows that well below the Fermi level the states are fully occupied, and well above the Fermi level, they are unoccupied. Near the Fermi level, the states go from occupied to unoccupied smoothly.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

mu = 0
k = 8.6e-5
T = 1000

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">f</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

espan = np.linspace(-10, 10, 200)
plt.plot(espan, f(espan))
plt.ylim([-0.1, 1.1])
plt.savefig(<span style="color: #228b22;">'images/fermi-entropy-integrand-1.png'</span>)
</pre>
</div>

<p><img src="/img/./images/fermi-entropy-integrand-1.png"><p>

<p>
Let us consider a simple density of states function, just a parabola. This could represent a s-band for example. We will use this function to explore the integral.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

mu = 0
k = 8.6e-5
T = 1000

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">f</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">dos</span>(e):
    d = (np.ones(e.shape) - 0.03 * e**2) 
    <span style="color: #8b0000;">return</span> d * (d &gt; 0)
espan = np.linspace(-10, 10)

plt.plot(espan, dos(espan), label=<span style="color: #228b22;">'Total dos'</span>)
plt.plot(espan, f(espan) * dos(espan), label=<span style="color: #228b22;">'Occupied states'</span>)
plt.legend(loc=<span style="color: #228b22;">'best'</span>)
plt.savefig(<span style="color: #228b22;">'images/fermi-entropy-integrand-2.png'</span>)
</pre>
</div>

<p>
<p><img src="/img/./images/fermi-entropy-integrand-2.png"><p>
Now, we consider the integral to compute the electronic entropy. The entropy is proportional to this integral.
</p>

<p>
\( \int n(\epsilon) (f \ln f + (1 - f) \ln (1-f)) d\epsilon \)
</p>

<p>
It looks straightforward to compute, but it turns out there is a wrinkle. Evaluating the integrand leads to <code>nan</code> elements because the ln(0) is -&infin;. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
mu = 0
k = 8.6e-5
T = 100

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">fermi</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

espan = np.array([-20, -10, -5, 0.0, 5, 10])
f = fermi(espan)

<span style="color: #8b0000;">print</span> f * np.log(f)
<span style="color: #8b0000;">print</span> (1 - f) * np.log(1 - f)
</pre>
</div>

<pre class="example">
[  0.00000000e+000   0.00000000e+000   0.00000000e+000  -3.46573590e-001
  -1.85216532e-250               nan]
[        nan         nan         nan -0.34657359  0.          0.        ]
</pre>

<p>
In this case, these <code>nan</code> elements should be equal to zero (x ln(x) goes to zero as x goes to zero). So, we can just ignore those elements in the integral. Here is how to do that.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

mu = 0
k = 8.6e-5
T = 1000

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">fermi</span>(e):
    <span style="color: #8b0000;">return</span> 1.0 / (np.exp((e - mu)/(k*T)) + 1)

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">dos</span>(e):
    d = (np.ones(e.shape) - 0.03 * e**2) 
    <span style="color: #8b0000;">return</span> d * (d &gt; 0)

espan = np.linspace(-20, 10)
f = fermi(espan)
n = dos(espan)

g = n * (f * np.log(f) + (1 - f) * np.log(1 - f))

<span style="color: #8b0000;">print</span> np.trapz(espan, g) <span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">nan because of the nan in the g vector</span>
<span style="color: #8b0000;">print</span> g

plt.plot(espan, g)
plt.savefig(<span style="color: #228b22;">'images/fermi-entropy-integrand-3.png'</span>)

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">find the elements that are not nan</span>
ind = np.logical_not(np.isnan(g))

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">evaluate the integrand for only those points</span>
<span style="color: #8b0000;">print</span> np.trapz(espan[ind], g[ind])
</pre>
</div>

<pre class="example">
nan
[             nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
  -9.75109643e-14  -1.05987106e-10  -1.04640574e-07  -8.76265644e-05
  -4.92684641e-02  -2.91047740e-01  -7.75652579e-04  -1.00962241e-06
  -1.06972936e-09  -1.00527877e-12  -8.36436686e-16  -6.48930917e-19
  -4.37946336e-22  -2.23285389e-25  -1.88578082e-29   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00]
0.208886080897
</pre>

<p><img src="/img/./images/fermi-entropy-integrand-3.png"><p>

<p>
The integrand is pretty well behaved in the figure above. You do not see the full range of the x-axis, because the integrand evaluates to <code>nan</code> for very negative numbers. This causes the <code>trapz</code> function to return <code>nan</code> also. We can solve the problem by only integrating the parts that are not <code>nan</code>. We have to use numpy.logical<sub>not</sub> to get an element-wise array of which elements are not <code>nan</code>. In this example, the integrand is not well sampled, so the area under that curve may not be very accurate. 
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/03/06/Integrating-the-Fermi-distribution-to-compute-entropy.org">org-mode source</a><p>