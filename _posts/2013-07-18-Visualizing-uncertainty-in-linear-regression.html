---
title: Visualizing uncertainty in linear regression
date: 2013/07/18 19:13:40
updated: 2013/07/18 19:13:40
categories: data analysis, uncertainty
tags: 
---




<p>
In this example, we show how to visualize  uncertainty in a fit. The idea is to fit a model to <a href="http://www.itl.nist.gov/div898/handbook/pmd/section4/pmd44.htm">data</a>, and get the uncertainty in the model parameters. Then we sample the parameters according to the normal distribution, and plot the corresponding distribution of models. We use transparent lines and allow the overlap to indicate the density of the fits.
</p>

<p>
The data is stored in a text file download PT.txt , with the following structure:
</p>

<pre class="example">
Run          Ambient                            Fitted
 Order  Day  Temperature  Temperature  Pressure    Value    Residual
  1      1      23.820      54.749      225.066   222.920     2.146
...
</pre>

<p>
We need to read the data in, and perform a regression analysis on P vs. T. In python we start counting at 0, so we actually want columns 3 and 4.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
<span style="color: #8b0000;">from</span> pycse <span style="color: #8b0000;">import</span> regress

data = np.loadtxt(<span style="color: #228b22;">'../../pycse/data/PT.txt'</span>, skiprows=2)
T = data[:, 3]
P = data[:, 4]

A = np.column_stack([T**0, T])

p, pint, se = regress(A, P, 0.05)

<span style="color: #8b0000;">print</span> p, pint, se
plt.plot(T, P, <span style="color: #228b22;">'k.'</span>)
plt.plot(T, np.dot(A, p))

<span style="color: #ff0000; font-weight: bold;"># Now we plot the distribution of possible lines</span>
N = 2000
B = np.random.normal(p[0], se[0], N)
M = np.random.normal(p[1], se[1], N)
x = np.array([<span style="color: #8b0000;">min</span>(T), <span style="color: #8b0000;">max</span>(T)])

<span style="color: #8b0000;">for</span> b,m <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(B, M):
    plt.plot(x, m*x + b, <span style="color: #228b22;">'-'</span>, color=<span style="color: #228b22;">'gray'</span>, alpha=0.02)
plt.savefig(<span style="color: #228b22;">'images/plotting-uncertainty.png'</span>)
</pre>
</div>

<pre class="example">
[ 7.74899739  3.93014044] [[  2.97964903  12.51834576]
 [  3.82740876   4.03287211]] [ 2.35384765  0.05070183]
</pre>

<p><img src="/img/./images/plotting-uncertainty.png"><p>

<p>
Here you can see 2000 different lines that have some probability of being correct. The darkest gray is near the fit, as expected; the darker the gray the more probable it is the line. This is a qualitative way of judging the quality of the fit.
</p>

<p>
Note, this is not the prediction error that we are plotting, that is the uncertainty in where a predicted y-value is. 
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/07/18/Visualizing-uncertainty-in-linear-regression.org">org-mode source</a><p>